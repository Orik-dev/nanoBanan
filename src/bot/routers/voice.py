# from __future__ import annotations

# import os
# import tempfile
# import logging
# import time
# from aiogram import Router, F
# from aiogram.types import Message
# from aiogram.fsm.context import FSMContext

# from speech_recognition import Recognizer, AudioFile, UnknownValueError, RequestError
# from pydub import AudioSegment
# from pydub.effects import normalize

# from core.config import settings
# from bot.states import GenStates, CreateStates
# from services.queue import enqueue_generation

# router = Router()
# logger = logging.getLogger("voice")

# # ffmpeg –¥–ª—è pydub
# AudioSegment.converter = settings.FFMPEG_PATH


# @router.message(F.voice)
# async def handle_voice_message(message: Message, state: FSMContext):
#     """
#     –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–æ–º—Ç–æ–≤:
#     - /gen: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –ø—Ä–æ–º—Ç –∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º —Ñ–æ—Ç–æ (GenStates.waiting_prompt)
#     - /create: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ —Ñ–æ—Ç–æ (CreateStates.waiting_prompt)
#     - CreateStates.selecting_aspect_ratio: –ø—Ä–∏–Ω—è—Ç—å –≥–æ–ª–æ—Å —Å—Ä–∞–∑—É, AR = None (–∞–≤—Ç–æ)
#     –í—Å–µ–≥–¥–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º ¬´–†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å‚Ä¶¬ª, —á—Ç–æ–±—ã –æ–Ω–æ –Ω–µ –æ—Å—Ç–∞–≤–∞–ª–æ—Å—å –≤–∏—Å—è—â–∏–º.
#     """
#     user_id = message.from_user.id
#     ogg_path = None
#     wav_path = None

#     current_state = await state.get_state()
#     data = await state.get_data()
#     logger.info(f"[VOICE] user={user_id} state={current_state}")

#     # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö
#     if current_state == GenStates.uploading_images.state:
#         await message.answer(
#             "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ 1‚Äì4 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å.\n"
#             "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π."
#         )
#         return

#     if current_state in (GenStates.generating.state, CreateStates.generating.state):
#         await message.answer("‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è. –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
#         return

#     if current_state == GenStates.final_menu.state:
#         await message.answer(
#             "‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
#             "–ù–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å, –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.\n"
#             "–î–ª—è –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî /gen (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ) –∏–ª–∏ /create (—Å–æ–∑–¥–∞–Ω–∏–µ)."
#         )
#         return

#     # –°–æ–æ–±—â–µ–Ω–∏–µ ¬´—Ä–∞—Å–ø–æ–∑–Ω–∞—é¬ª ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º/–∑–∞–º–µ–Ω–∏–º
#     processing_msg = await message.answer("üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å...")

#     try:
#         # –°–∫–∞—á–∞—Ç—å voice –∏–∑ Telegram
#         file = await message.bot.get_file(message.voice.file_id)
#         voice_data = await message.bot.download_file(file.file_path)

#         # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å .ogg
#         with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg_file:
#             ogg_file.write(voice_data.getvalue())
#             ogg_path = ogg_file.name

#         # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å/–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å ‚Üí .wav 16kHz mono
#         audio = AudioSegment.from_file(ogg_path, format="ogg")
#         audio = normalize(audio)
#         if audio.channels > 1:
#             audio = audio.set_channels(1)
#         audio = audio.set_frame_rate(16000)
#         wav_path = ogg_path.replace(".ogg", ".wav")
#         audio.export(wav_path, format="wav", parameters=["-ar", "16000", "-ac", "1"])

#         # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
#         r = Recognizer()
#         r.energy_threshold = 300
#         r.dynamic_energy_threshold = True
#         r.pause_threshold = 0.5
#         r.non_speaking_duration = 0.3

#         with AudioFile(wav_path) as src:
#             r.adjust_for_ambient_noise(src, duration=0.3)
#             audio_data = r.record(src)

#         text = r.recognize_google(audio_data, language="ru-RU", show_all=False).strip()

#         if not text or len(text) < 2:
#             await processing_msg.edit_text(
#                 "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.\n\n"
#                 "üí° –°–æ–≤–µ—Ç—ã:\n"
#                 "‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç—á–µ –∏ –≥—Ä–æ–º—á–µ\n"
#                 "‚Ä¢ –ó–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ 2‚Äì3 —Å–µ–∫—É–Ω–¥—ã –∏ –¥–æ–ª—å—à–µ\n"
#                 "‚Ä¢ –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω–æ–≥–æ —à—É–º–∞"
#             )
#             return

#         # –ü–æ–∫–∞–∂–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –ø—Ä–æ–º—Ç (—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ)
#         try:
#             await processing_msg.edit_text(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
#         except Exception:
#             # –ï—Å–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–ª—å–∑—è ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏ —É–¥–∞–ª–∏–º ¬´—Ä–∞—Å–ø–æ–∑–Ω–∞—é¬ª
#             await message.answer(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
#             try:
#                 await processing_msg.delete()
#             except Exception:
#                 pass

#         # ===== –í–µ—Ç–≤–∏ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º =====
#         # /gen: —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ
#         if current_state == GenStates.waiting_prompt.state:
#             photos = data.get("photos") or []
#             if not photos:
#                 await message.answer("‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /gen –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–Ω–∞—á–∞–ª–∞.")
#                 return

#             file_ids = [p["file_id"] for p in photos]
#             wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

#             await state.set_state(GenStates.generating)
#             await state.update_data(
#                 prompt=text,
#                 base_prompt=text,
#                 edits=[],
#                 mode="edit",
#                 wait_msg_id=wait_msg.message_id,
#                 gen_started_at=int(time.time()),
#             )
#             await enqueue_generation(user_id, text, file_ids)
#             return

#         # /create: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ —Ñ–æ—Ç–æ
#         if current_state == CreateStates.waiting_prompt.state:
#             aspect_ratio = (data.get("aspect_ratio") or None)
#             wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

#             await state.set_state(CreateStates.generating)
#             await state.update_data(
#                 mode="create",
#                 prompt=text,
#                 wait_msg_id=wait_msg.message_id,
#                 gen_started_at=int(time.time()),
#             )
#             await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
#             return

#         # –ì–æ–ª–æ—Å –ø—Ä–∏—à—ë–ª –ø–æ–∫–∞ –∂–¥—ë–º –≤—ã–±–æ—Ä AR ‚Üí –±–µ—Ä—ë–º –∞–≤—Ç–æ (None) –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
#         if current_state == CreateStates.selecting_aspect_ratio.state:
#             aspect_ratio = (data.get("aspect_ratio") or None)
#             wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

#             await state.set_state(CreateStates.generating)
#             await state.update_data(
#                 mode="create",
#                 prompt=text,
#                 wait_msg_id=wait_msg.message_id,
#                 gen_started_at=int(time.time()),
#                 aspect_ratio=aspect_ratio,
#             )
#             await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
#             return

#         # –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ‚Äî –ø–æ–¥—Å–∫–∞–∂–µ–º –∫–æ–º–∞–Ω–¥—ã
#         await message.answer(
#             "‚ÑπÔ∏è –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n\n"
#             "‚Ä¢ <b>/gen</b> ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ (–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º —Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç)\n"
#             "‚Ä¢ <b>/create</b> ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç —Å—Ä–∞–∑—É)",
#             parse_mode="HTML"
#         )

#     except UnknownValueError:
#         try:
#             await processing_msg.edit_text(
#                 "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\n\n"
#                 "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –æ—Ç—á—ë—Ç–ª–∏–≤–µ–µ –∏ –∏–∑–±–µ–≥–∞—Ç—å —à—É–º–∞."
#             )
#         except Exception:
#             await message.answer(
#                 "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\n\n"
#                 "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –æ—Ç—á—ë—Ç–ª–∏–≤–µ–µ –∏ –∏–∑–±–µ–≥–∞—Ç—å —à—É–º–∞."
#             )
#     except RequestError as e:
#         logger.error(f"[VOICE] Google API error: {e}")
#         try:
#             await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
#         except Exception:
#             await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
#     except Exception:
#         logger.exception("[VOICE] Unexpected error")
#         try:
#             await processing_msg.edit_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
#         except Exception:
#             await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
#     finally:
#         # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
#         for p in (ogg_path, wav_path):
#             if p and os.path.exists(p):
#                 try:
#                     os.remove(p)
#                 except Exception:
#                     pass


from __future__ import annotations

import os
import tempfile
import logging
import time
from aiogram import Router, F
from aiogram.types import Message
from aiogram.fsm.context import FSMContext

from speech_recognition import Recognizer, AudioFile, UnknownValueError, RequestError
from pydub import AudioSegment
from pydub.effects import normalize

from core.config import settings
from bot.states import GenStates, CreateStates
from services.queue import enqueue_generation

router = Router()
logger = logging.getLogger("voice")

# –ø—É—Ç—å –∫ ffmpeg –¥–ª—è pydub
AudioSegment.converter = settings.FFMPEG_PATH


@router.message(F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """
    –ì–æ–ª–æ—Å–æ–≤–æ–π –ø—Ä–æ–º—Ç –¥–ª—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π:
    - GenStates.waiting_prompt: —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
    - GenStates.final_menu: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∫–∏ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –∏ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    - CreateStates.waiting_prompt: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–µ–∑ —Ñ–æ—Ç–æ
    - CreateStates.selecting_aspect_ratio: –≥–æ–ª–æ—Å —Å—Ä–∞–∑—É ‚Üí AR=auto –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    """
    user_id = message.from_user.id
    ogg_path = None
    wav_path = None

    cur = await state.get_state()
    data = await state.get_data()
    logger.info(f"[VOICE] user={user_id} state={cur}")

    # –ë–ª–æ–∫–∏—Ä—É–µ–º –≥–æ–ª–æ—Å —Ç–∞–º, –≥–¥–µ —ç—Ç–æ —Ç–æ—á–Ω–æ –Ω–µ –Ω—É–∂–Ω–æ
    if cur == GenStates.uploading_images.state:
        await message.answer(
            "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ 1‚Äì4 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å.\n"
            "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–π."
        )
        return
    if cur in (GenStates.generating.state, CreateStates.generating.state):
        await message.answer("‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è. –ü–æ—Ç–æ–º –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.")
        return

    # –°–æ–æ–±—â–µ–Ω–∏–µ ¬´—Ä–∞—Å–ø–æ–∑–Ω–∞—é‚Ä¶¬ª ‚Äî –¥–∞–ª—å—à–µ –µ–≥–æ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º/—É–¥–∞–ª–∏–º
    processing_msg = await message.answer("üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å...")

    try:
        # --- –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ ---
        file = await message.bot.get_file(message.voice.file_id)
        voice_data = await message.bot.download_file(file.file_path)
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg_file:
            ogg_file.write(voice_data.getvalue())
            ogg_path = ogg_file.name

        audio = AudioSegment.from_file(ogg_path, format="ogg")
        audio = normalize(audio).set_channels(1).set_frame_rate(16000)
        wav_path = ogg_path.replace(".ogg", ".wav")
        audio.export(wav_path, format="wav", parameters=["-ar", "16000", "-ac", "1"])

        # --- —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ---
        r = Recognizer()
        r.energy_threshold = 300
        r.dynamic_energy_threshold = True
        r.pause_threshold = 0.5
        r.non_speaking_duration = 0.3

        with AudioFile(wav_path) as src:
            r.adjust_for_ambient_noise(src, duration=0.3)
            audio_data = r.record(src)

        text = r.recognize_google(audio_data, language="ru-RU", show_all=False).strip()
        if not text or len(text) < 2:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.\n\n"
                "üí° –ì–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç—á–µ, –∑–∞–ø–∏—à–∏—Ç–µ 2‚Äì3 —Å–µ–∫—É–Ω–¥—ã –∏ –∏–∑–±–µ–≥–∞–π—Ç–µ —à—É–º–∞."
            )
            return

        # –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –ø—Ä–æ–º—Ç
        try:
            await processing_msg.edit_text(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
        except Exception:
            await message.answer(f"üéôÔ∏è <b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n\n<i>{text}</i>", parse_mode="HTML")
            try:
                await processing_msg.delete()
            except Exception:
                pass

        # ---------- –í–ï–¢–í–ò –ü–û –°–û–°–¢–û–Ø–ù–ò–Æ ----------

        # /gen: –∂–¥—ë–º –ø—Ä–æ–º—Ç –¥–ª—è —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
        if cur == GenStates.waiting_prompt.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /gen –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å–Ω–∞—á–∞–ª–∞.")
                return
            file_ids = [p["file_id"] for p in photos]

            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=text,
                base_prompt=text,
                edits=[],
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, text, file_ids)
            return

        # ‚úÖ –ù–û–í–û–ï: –≥–æ–ª–æ—Å–æ–≤—ã–µ –ø—Ä–∞–≤–∫–∏ –ø–æ—Å–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ /gen
        if cur == GenStates.final_menu.state:
            photos = data.get("photos") or []
            if not photos:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ù–∞–∂–º–∏—Ç–µ ¬´–ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ¬ª.")
                return

            base_prompt = (data.get("base_prompt") or data.get("prompt") or "").strip()
            edits = list(data.get("edits") or [])
            edits.append(text)
            cumulative_prompt = " ".join([base_prompt] + edits).strip()
            if len(cumulative_prompt) > 4000:
                cumulative_prompt = cumulative_prompt[:4000]

            file_ids = [p["file_id"] for p in photos]
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

            await state.set_state(GenStates.generating)
            await state.update_data(
                prompt=cumulative_prompt,
                base_prompt=base_prompt,
                edits=edits,
                mode="edit",
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, cumulative_prompt, file_ids)
            return

        # /create: –æ–±—ã—á–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø—Ä–æ–º—Ç–∞
        if cur == CreateStates.waiting_prompt.state:
            aspect_ratio = data.get("aspect_ratio") or None
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
            )
            await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
            return

        # /create: –≥–æ–ª–æ—Å –ø—Ä–∏—à—ë–ª, –ø–æ–∫–∞ –∂–¥—ë–º –≤—ã–±–æ—Ä AR ‚Äî –±–µ—Ä—ë–º –∞–≤—Ç–æ
        if cur == CreateStates.selecting_aspect_ratio.state:
            aspect_ratio = data.get("aspect_ratio") or None
            wait_msg = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")
            await state.set_state(CreateStates.generating)
            await state.update_data(
                mode="create",
                prompt=text,
                wait_msg_id=wait_msg.message_id,
                gen_started_at=int(time.time()),
                aspect_ratio=aspect_ratio,
            )
            await enqueue_generation(user_id, text, [], aspect_ratio=aspect_ratio)
            return

        # –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏
        await message.answer(
            "‚ÑπÔ∏è –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
            "‚Ä¢ <b>/gen</b> ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ (–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º —Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç)\n"
            "‚Ä¢ <b>/create</b> ‚Äî —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫–∞–∂–∏—Ç–µ –ø—Ä–æ–º—Ç —Å—Ä–∞–∑—É)",
            parse_mode="HTML",
        )

    except UnknownValueError:
        try:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –æ—Ç—á—ë—Ç–ª–∏–≤–µ–µ –∏ –∏–∑–±–µ–≥–∞—Ç—å —à—É–º–∞."
            )
        except Exception:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    except RequestError as e:
        logger.error(f"[VOICE] Google API error: {e}")
        try:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        except Exception:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è Google. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
    except Exception:
        logger.exception("[VOICE] Unexpected error")
        try:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        except Exception:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
    finally:
        # —á–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for p in (ogg_path, wav_path):
            if p and os.path.exists(p):
                try:
                    os.remove(p)
                except Exception:
                    pass
